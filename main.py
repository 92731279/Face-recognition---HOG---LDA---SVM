import os
import cv2
import numpy as np
import pandas as pd
from skimage.feature import hog
from sklearn.preprocessing import LabelEncoder
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

# === Ã‰tape 1 : Chargement des images dans un DataFrame ===
image_dir = 'C:\\Users\\wided\\OneDrive\\Desktop\\1misids\\s2\\python\\FEI BD'
file_list = [f for f in os.listdir(image_dir) if f.endswith(".jpg") or f.endswith(".png")]

df = pd.DataFrame({'filename': file_list})
df['image_path'] = df['filename'].apply(lambda f: os.path.join(image_dir, f))

# Regroupement des images par personne (label = personne)
df['label'] = df['filename'].apply(lambda f: f.split('-')[0])  # Regrouper par personne, par exemple '1'

df['image'] = df['image_path'].apply(cv2.imread)

print(f"âœ… Ã‰tape 1 : {len(df)} images chargÃ©es.")
print("ğŸ” Exemple de labels :", df['label'].unique()[:5])
plt.imshow(cv2.cvtColor(df['image'][0], cv2.COLOR_BGR2RGB))
plt.title("Image originale")
plt.axis('off')
plt.show()

# === Ã‰tape 2 : PrÃ©traitement ===
def preprocess_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    resized = cv2.resize(gray, (100, 100))
    _, binary = cv2.threshold(resized, 127, 1, cv2.THRESH_BINARY)
    return binary.astype(np.float32)

df['preprocessed'] = df['image'].apply(preprocess_image)

print("âœ… Ã‰tape 2 : PrÃ©traitement terminÃ© (niveaux de gris + binarisation).")
plt.imshow(df['preprocessed'][0], cmap='gray')
plt.title("Image prÃ©traitÃ©e")
plt.axis('off')
plt.show()

# === Ã‰tape 3 : DÃ©tection de visages ===
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def detect_face(image):
    image = (image * 255).astype(np.uint8)
    faces = face_cascade.detectMultiScale(image, 1.1, 4)
    for (x, y, w, h) in faces:
        return cv2.resize(image[y:y+h, x:x+w], (64, 64))
    return cv2.resize(image, (64, 64))

df['face'] = df['preprocessed'].apply(detect_face)

print("âœ… Ã‰tape 3 : Visages dÃ©tectÃ©s.")
plt.imshow(df['face'][0], cmap='gray')
plt.title("Visage dÃ©tectÃ©")
plt.axis('off')
plt.show()

# === Ã‰tape 4 : Extraction de caractÃ©ristiques HOG ===
def extract_hog_features(image):
    return hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2),
               orientations=9, block_norm='L2-Hys')

df['features'] = df['face'].apply(extract_hog_features)

X = np.stack(df['features'].to_numpy())
le = LabelEncoder()
y = le.fit_transform(df['label'])

print("âœ… Ã‰tape 4 : Extraction des caractÃ©ristiques HOG terminÃ©e.")
print("ğŸ”¢ Exemple de vecteur de caractÃ©ristiques HOG :", X[0][:10])  # 10 premiÃ¨res valeurs

# === Ã‰tape 5 : RÃ©duction dimensionnelle avec LDA ===
lda = LinearDiscriminantAnalysis()
X_lda = lda.fit_transform(X, y)

print(f"âœ… Ã‰tape 5 : RÃ©duction de dimensions avec LDA -> Dimensions : {X_lda.shape}")

# === Ã‰tape 6 : SVM avec GridSearch ===
X_train, X_test, y_train, y_test = train_test_split(X_lda, y, test_size=0.2, random_state=42)

param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf']
}

grid = GridSearchCV(SVC(), param_grid, cv=5)
grid.fit(X_train, y_train)

print("\nâœ… Ã‰tape 6 : EntraÃ®nement du SVM terminÃ© avec GridSearch.")
print("ğŸ” Meilleur score :", grid.best_score_)
print("âš™ï¸ Meilleurs hyperparamÃ¨tres :", grid.best_params_)

# === Ã‰tape 7 : Ã‰valuation ===
y_pred = grid.predict(X_test)
print("\nâœ… Ã‰tape 7 : Ã‰valuation du modÃ¨le.")
print("ğŸ“Š Rapport de classification :\n", classification_report(y_test, y_pred))
print("ğŸ¯ Accuracy :", accuracy_score(y_test, y_pred))

# === Matrice de confusion ===
plt.figure(figsize=(10, 8))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=False, fmt='d', cmap='Blues')
plt.title("Matrice de confusion")
plt.xlabel("PrÃ©dictions")
plt.ylabel("RÃ©el")
plt.show()
